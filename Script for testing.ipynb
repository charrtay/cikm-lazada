{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def write_submission(filename, predicted_results):\n",
    "    if not os.path.exists('submission'):\n",
    "        os.makedirs('submission')\n",
    "    np.savetxt('submission/' + filename, predicted_results, fmt='%.5f')\n",
    "    print(filename + ' updated!')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "word_parser = RegexpTokenizer('[A-Za-z]+', flags=re.UNICODE)\n",
    "digit_checker = re.compile(\"\\d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "country\n",
    "price\n",
    "level 1 category\n",
    "level 2 category\n",
    "title keyword density\n",
    "title length\n",
    "has duplicate tokens\n",
    "sum of tf-idf values per title\n",
    "average tf-idf value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_description(description):\n",
    "    description = BeautifulSoup(description, \"html5lib\")\n",
    "    description = description.getText(' ')\n",
    "    \n",
    "    tokens = word_parser.tokenize(description)\n",
    "    \n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = list(filter(lambda t: t not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u'x'], tokens))\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def tokenize_title(title):\n",
    "    try:\n",
    "        title = ''.join(i for i in title if ord(i)<128)\n",
    "        tokens_ = [word_tokenize(sent) for sent in sent_tokenize(title)]\n",
    "        \n",
    "        tokens = []\n",
    "        for token_by_sent in tokens_:\n",
    "            tokens += token_by_sent\n",
    "\n",
    "        tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "        tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "        tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u\"''\", u'``', u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "        \n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            if re.search('[a-zA-Z]', token):\n",
    "                filtered_tokens.append(token)\n",
    "\n",
    "        filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "\n",
    "        return filtered_tokens\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def extract_title_features(titles):\n",
    "    title_features = np.zeros((len(titles),3))\n",
    "    \n",
    "    for index in range(len(titles)):\n",
    "        title = titles[index]\n",
    "        \n",
    "        # Check if title contains non-ascii characters\n",
    "        try:\n",
    "            title.decode('ascii')\n",
    "        except:\n",
    "            title_features[index,0] = 1.\n",
    "            \n",
    "        # Compute the number of tokens title contains\n",
    "        tokens = tokenize_title(title)\n",
    "        title_features[index,1] = len(title)\n",
    "        \n",
    "        # Check if title contains a number\n",
    "        if digit_checker.search(title):\n",
    "            title_features[index,2] = 1.\n",
    "    \n",
    "    return title_features\n",
    "\n",
    "        \n",
    "def has_duplicates(values):\n",
    "    # For each element, check all following elements for a duplicate.\n",
    "    for i in range(0, len(values)):\n",
    "        for x in range(i + 1, len(values)):\n",
    "            if values[i] == values[x]:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def calculate_tfidf_sum(tokens):\n",
    "    score = 0\n",
    "    for token in tokens:\n",
    "        if tfidf.tfidf.get(token) is not None:\n",
    "            score = score + tfidf.tfidf.get(token)\n",
    "    return score\n",
    "\n",
    "def calculate_tfidf_mean(tokens):\n",
    "    score = 0\n",
    "    for token in tokens:\n",
    "        if tfidf.tfidf.get(token) is not None:\n",
    "            score = score + tfidf.tfidf.get(token)\n",
    "    if len(tokens)>1:\n",
    "        mean = score/len(tokens)\n",
    "    else:\n",
    "        mean = 0\n",
    "    return mean\n",
    "\n",
    "def keyword_density(title):\n",
    "    count = 0\n",
    "    length = len(title)\n",
    "    for word in title:\n",
    "        if word in tfidf.index:\n",
    "            count += 1\n",
    "    density = count/length if count>1 else 0\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer='data/training/data_train.csv', \n",
    "                 names=['country','sku_id','title','category_lvl_1','category_lvl_2','category_lvl_3','short_description','price','product_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "# Compute tf-idf on descriptions\n",
    "tf_idf_desription = TfidfVectorizer(min_df=10, max_features=10000, tokenizer=tokenize_description, ngram_range=(1, 2))\n",
    "\n",
    "descriptions = df_train['short_description'].replace(np.nan, '')\n",
    "descriptions = tf_idf_desription.fit_transform(list(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute tf-idf on titles\n",
    "tf_idf_title = TfidfVectorizer(min_df=10, max_features=10000, tokenizer=tokenize_title, ngram_range=(1, 2))\n",
    "\n",
    "titles = tf_idf_title.fit_transform(list(df_train['title']))\n",
    "df_train['tokenized_title'] = df_train['title'].map(tokenize_title)\n",
    "\n",
    "tfidf = dict(zip(tf_idf_title.get_feature_names(), tf_idf_title.idf_))\n",
    "tfidf = pd.DataFrame(columns=['tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute title keyword density\n",
    "titleKeywordDensity = df_train['tokenized_title'].map(keyword_density)\n",
    "\n",
    "# Compute title length\n",
    "titleLength = df_train['tokenized_title'].map(len)\n",
    "\n",
    "# Compute new feature - 1 if title has duplicates, 0 if not.\n",
    "hasDuplicateTokens = df_train['tokenized_title'].map(has_duplicates)\n",
    "\n",
    "# Compute tf-idf sum\n",
    "tfidfSum = df_train['tokenized_title'].map(calculate_tfidf_sum)\n",
    "\n",
    "# Compute tf-idf average\n",
    "tfidfAvg = df_train['tokenized_title'].map(calculate_tfidf_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract other features of titles\n",
    "title_features = extract_title_features(df_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT INPUTS AND OUTPUTS\n",
    "X = np.concatenate([titles.toarray(),\n",
    "                    title_features,\n",
    "                    descriptions.toarray(),\n",
    "                    titleKeywordDensity.as_matrix().reshape(-1,1),\n",
    "                    titleLength.as_matrix().reshape(-1,1),\n",
    "                    hasDuplicateTokens.as_matrix().reshape(-1,1),\n",
    "                    tfidfSum.as_matrix().reshape(-1,1),\n",
    "                    tfidfAvg.as_matrix().reshape(-1,1),\n",
    "                    pd.get_dummies(df_train['category_lvl_1']).as_matrix(), \n",
    "                    pd.get_dummies(df_train['category_lvl_2']).as_matrix(),\n",
    "                    pd.get_dummies(df_train['category_lvl_3']).as_matrix(),\n",
    "                    pd.get_dummies(df_train['product_type']).as_matrix(),\n",
    "                    df_train['price'].as_matrix().reshape(-1,1),\n",
    "                    (df_train.product_type == 'local').as_matrix().astype(float).reshape(-1,1)\n",
    "                   ], \n",
    "                   axis=1)\n",
    "\n",
    "y = pd.read_csv(\"data/training/clarity_train.labels\", header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 0.210334\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train and evaluate the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model RMSE: %f\" % mean_squared_error(model.predict_proba(X_test)[:,1], y_test)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clarity_valid.predict updated!\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission\n",
    "\n",
    "df_valid = pd.read_csv(filepath_or_buffer='data/validation/data_valid.csv', \n",
    "                       names=['country','sku_id','title','category_lvl_1','category_lvl_2','category_lvl_3','short_description','price','product_type'])\n",
    "\n",
    "# Perform tf-idf of descriptions\n",
    "descriptions = df_valid['short_description'].replace(np.nan, '')\n",
    "descriptions = tf_idf_desription.transform(list(descriptions))\n",
    "\n",
    "\n",
    "# Compute tf-idf of title\n",
    "titles = tf_idf_title.transform(list(df_valid['title']))\n",
    "df_valid['tokenized_title'] = df_valid['title'].map(tokenize_title)\n",
    "\n",
    "tfidf = dict(zip(tf_idf_title.get_feature_names(), tf_idf_title.idf_))\n",
    "tfidf = pd.DataFrame(columns=['tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['tfidf']\n",
    "\n",
    "\n",
    "# Compute title keyword density\n",
    "titleKeywordDensity = df_valid['tokenized_title'].map(keyword_density)\n",
    "\n",
    "# Compute title length\n",
    "titleLength = df_valid['tokenized_title'].map(len)\n",
    "\n",
    "# Compute new feature - 1 if title has duplicates, 0 if not.\n",
    "hasDuplicateTokens = df_valid['tokenized_title'].map(has_duplicates)\n",
    "\n",
    "# Compute tf-idf sum\n",
    "tfidfSum = df_valid['tokenized_title'].map(calculate_tfidf_sum)\n",
    "\n",
    "# Compute tf-idf average\n",
    "tfidfAvg = df_valid['tokenized_title'].map(calculate_tfidf_mean)\n",
    "\n",
    "# Extract other features of titles\n",
    "title_features = extract_title_features(df_valid['title'])\n",
    "\n",
    "# Construct inputs and outputs\n",
    "X_valid = np.concatenate([titles.toarray(),\n",
    "                          title_features,\n",
    "                          descriptions.toarray(),\n",
    "                          titleKeywordDensity.as_matrix().reshape(-1,1),\n",
    "                          titleLength.as_matrix().reshape(-1,1),\n",
    "                          hasDuplicateTokens.as_matrix().reshape(-1,1),\n",
    "                          tfidfSum.as_matrix().reshape(-1,1),\n",
    "                          tfidfAvg.as_matrix().reshape(-1,1),\n",
    "                          pd.get_dummies(df_valid['category_lvl_1']).as_matrix(), \n",
    "                          pd.get_dummies(df_valid['category_lvl_2']).as_matrix(),\n",
    "                          pd.get_dummies(df_valid['category_lvl_3']).as_matrix(),\n",
    "                          pd.get_dummies(df_valid['product_type']).as_matrix(),\n",
    "                          df_valid['price'].as_matrix().reshape(-1,1),\n",
    "                          (df_valid.product_type == 'local').as_matrix().astype(float).reshape(-1,1)\n",
    "                         ], \n",
    "                         axis=1)\n",
    "\n",
    "\n",
    "# Retrain the model on the whole dataset\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "predicted_results = model.predict_proba(X_valid)[:, 1]\n",
    "write_submission('clarity_valid.predict', predicted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 0.343862\n"
     ]
    }
   ],
   "source": [
    "# CONSTRUCT INPUTS AND OUTPUTS\n",
    "y = pd.read_csv(\"data/training/conciseness_train.labels\", header=None).as_matrix().ravel()\n",
    "\n",
    "# SPLIT INTO TRAINING SET AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# TRAIN AND EVALUATE THE MODEL\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model RMSE: %f\" % mean_squared_error(model.predict_proba(X_test)[:,1], y_test)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conciseness_valid.predict updated!\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN THE MODEL ON THE WHOLE DATASET\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "predicted_results = model.predict_proba(X_valid)[:, 1]\n",
    "write_submission('conciseness_valid.predict', predicted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('zip -j submission submission/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
